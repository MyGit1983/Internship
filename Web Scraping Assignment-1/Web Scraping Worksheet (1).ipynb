{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Scraping Worksheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting bs4\n",
      "  Downloading bs4-0.0.1.tar.gz (1.1 kB)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\user\\anaconda3\\lib\\site-packages (from bs4) (4.9.3)\n",
      "Requirement already satisfied: soupsieve>1.2; python_version >= \"3.0\" in c:\\users\\user\\anaconda3\\lib\\site-packages (from beautifulsoup4->bs4) (2.0.1)\n",
      "Building wheels for collected packages: bs4\n",
      "  Building wheel for bs4 (setup.py): started\n",
      "  Building wheel for bs4 (setup.py): finished with status 'done'\n",
      "  Created wheel for bs4: filename=bs4-0.0.1-py3-none-any.whl size=1277 sha256=7f9f97d91680334e11371a12c5ee6c9c3e191214d63eaefa65d4366c4f9158ab\n",
      "  Stored in directory: c:\\users\\user\\appdata\\local\\pip\\cache\\wheels\\75\\78\\21\\68b124549c9bdc94f822c02fb9aa3578a669843f9767776bca\n",
      "Successfully built bs4\n",
      "Installing collected packages: bs4\n",
      "Successfully installed bs4-0.0.1\n",
      "Requirement already satisfied: requests in c:\\users\\user\\anaconda3\\lib\\site-packages (2.24.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests) (2020.6.20)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests) (1.25.11)\n"
     ]
    }
   ],
   "source": [
    "!pip install bs4\n",
    "!pip install requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q.1 Write a python program to display all the header tags from‘en.wikipedia.org/wiki/Main_Page’."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Headers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>From today's featured article</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Did you know</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>In the news</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>On this day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Today's featured picture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Other areas of Wikipedia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Wikipedia's sister projects</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Wikipedia languages</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Headers\n",
       "0  From today's featured article\n",
       "1                   Did you know\n",
       "2                    In the news\n",
       "3                    On this day\n",
       "4       Today's featured picture\n",
       "5       Other areas of Wikipedia\n",
       "6    Wikipedia's sister projects\n",
       "7            Wikipedia languages"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "page = requests.get('https://en.wikipedia.org/wiki/Main_Page')\n",
    "soup = BeautifulSoup(page.content)\n",
    "\n",
    "headers_tags=soup.find_all('span',class_='mw-headline')\n",
    "\n",
    "headers=[]\n",
    "for i in headers_tags:\n",
    "    headers.append(i.text.replace('\\xa0...',''))\n",
    "    \n",
    "#print(headers)\n",
    "\n",
    "data=pd.DataFrame()\n",
    "data['Headers']=headers\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q.2 Write a python program to display IMDB’s Top rated 100 movies’ data (i.e. Name, IMDB rating, Year of release).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Movie Names</th>\n",
       "      <th>Relasing Year</th>\n",
       "      <th>Ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Shawshank Redemption</td>\n",
       "      <td>1927</td>\n",
       "      <td>9.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Godfather</td>\n",
       "      <td>1927</td>\n",
       "      <td>9.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Godfather: Part II</td>\n",
       "      <td>1927</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Dark Knight</td>\n",
       "      <td>1927</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12 Angry Men</td>\n",
       "      <td>1927</td>\n",
       "      <td>8.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Requiem for a Dream</td>\n",
       "      <td>1927</td>\n",
       "      <td>8.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Dune</td>\n",
       "      <td>1927</td>\n",
       "      <td>8.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Singin' in the Rain</td>\n",
       "      <td>1927</td>\n",
       "      <td>8.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>North by Northwest</td>\n",
       "      <td>1927</td>\n",
       "      <td>8.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>.      Eternal Sunshine of the Spotless Mind</td>\n",
       "      <td>1927</td>\n",
       "      <td>8.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Movie Names Relasing Year Ratings\n",
       "0                       The Shawshank Redemption          1927     9.2\n",
       "1                                  The Godfather          1927     9.1\n",
       "2                         The Godfather: Part II          1927     9.0\n",
       "3                                The Dark Knight          1927     9.0\n",
       "4                                   12 Angry Men          1927     8.9\n",
       "..                                           ...           ...     ...\n",
       "95                           Requiem for a Dream          1927     8.3\n",
       "96                                          Dune          1927     8.3\n",
       "97                           Singin' in the Rain          1927     8.3\n",
       "98                            North by Northwest          1927     8.3\n",
       "99  .      Eternal Sunshine of the Spotless Mind          1927     8.3\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "page = requests.get('https://www.imdb.com/chart/top')\n",
    "\n",
    "soup= BeautifulSoup(page.content)\n",
    "movienames=soup.find_all('td',class_='titleColumn')\n",
    "\n",
    "list_names=[]\n",
    "for i in movienames:\n",
    "    name=(i.text[10:-7]).replace('\\n','')\n",
    "    list_names.append(name)\n",
    "relasing_Year = soup.find_all('span',class_='secondaryInfo')    \n",
    "\n",
    "years=[]\n",
    "for i in relasing_Year:\n",
    "    year=i.text[1:-1]\n",
    "    years.append(year)\n",
    "    \n",
    "Ratings = soup.find_all('td',class_='ratingColumn imdbRating') \n",
    "\n",
    "ratings=[]\n",
    "for i in Ratings:\n",
    "    ratings.append(i.text.replace('\\n',''))\n",
    "    \n",
    "data=pd.DataFrame()\n",
    "data['Movie Names']=list_names\n",
    "data['Relasing Year']=year\n",
    "data['Ratings'] = ratings\n",
    "data.head(100)    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q.3 Write a python program to display IMDB’s Top rated 100 Indian movies’ data (i.e. Name, IMDB rating, Year of release)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Movie Names</th>\n",
       "      <th>Relasing Year</th>\n",
       "      <th>Ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Nayakan</td>\n",
       "      <td>2016</td>\n",
       "      <td>8.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Anbe Sivam</td>\n",
       "      <td>2016</td>\n",
       "      <td>8.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Pariyerum Perumal</td>\n",
       "      <td>2016</td>\n",
       "      <td>8.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C/o Kancharapalem</td>\n",
       "      <td>2016</td>\n",
       "      <td>8.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Golmaal</td>\n",
       "      <td>2016</td>\n",
       "      <td>8.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Rang De Basanti</td>\n",
       "      <td>2016</td>\n",
       "      <td>8.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>OMG: Oh My God!</td>\n",
       "      <td>2016</td>\n",
       "      <td>8.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Roja</td>\n",
       "      <td>2016</td>\n",
       "      <td>8.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Uri: The Surgical Strike</td>\n",
       "      <td>2016</td>\n",
       "      <td>8.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>.      Lagaan: Once Upon a Time in India</td>\n",
       "      <td>2016</td>\n",
       "      <td>8.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Movie Names Relasing Year Ratings\n",
       "0                                    Nayakan          2016     8.5\n",
       "1                                 Anbe Sivam          2016     8.5\n",
       "2                          Pariyerum Perumal          2016     8.5\n",
       "3                          C/o Kancharapalem          2016     8.5\n",
       "4                                    Golmaal          2016     8.5\n",
       "..                                       ...           ...     ...\n",
       "95                           Rang De Basanti          2016     8.1\n",
       "96                           OMG: Oh My God!          2016     8.1\n",
       "97                                      Roja          2016     8.1\n",
       "98                  Uri: The Surgical Strike          2016     8.1\n",
       "99  .      Lagaan: Once Upon a Time in India          2016     8.1\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "page = requests.get('https://www.imdb.com/india/top-rated-indian-movies/')\n",
    "\n",
    "soup= BeautifulSoup(page.content)\n",
    "\n",
    "movienames=soup.find_all('td',class_='titleColumn')\n",
    "\n",
    "list_names=[]\n",
    "for i in movienames:\n",
    "    name=(i.text[10:-7]).replace('\\n','')\n",
    "    list_names.append(name)\n",
    "\n",
    "relasing_Year = soup.find_all('span',class_='secondaryInfo')\n",
    "\n",
    "years=[]\n",
    "for i in relasing_Year:\n",
    "    year=i.text[1:-1]\n",
    "    years.append(year)\n",
    "    \n",
    "Ratings = soup.find_all('td',class_='ratingColumn imdbRating')  \n",
    "\n",
    "ratings=[]\n",
    "for i in Ratings:\n",
    "    ratings.append(i.text.replace('\\n',''))\n",
    "\n",
    "data=pd.DataFrame()\n",
    "data['Movie Names']=list_names\n",
    "data['Relasing Year']=year\n",
    "data['Ratings'] = ratings\n",
    "data.head(100)    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q.4 Write a python program to scrap book name, author name, genre and book review of any 5 books from 'www.bookpage.com’\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Book Name</th>\n",
       "      <th>Author</th>\n",
       "      <th>genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A Calling for Charlie Barnes</td>\n",
       "      <td>Joshua Ferris</td>\n",
       "      <td>Fiction / Family Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Playing the Cards You're Dealt</td>\n",
       "      <td>Varian Johnson</td>\n",
       "      <td>Children's / Middle Grade</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Please Don't Sit on My Bed in Your Outside Clo...</td>\n",
       "      <td>Phoebe Robinson</td>\n",
       "      <td>Nonfiction / Essays / Humor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Horseman</td>\n",
       "      <td>Christina Henry</td>\n",
       "      <td>Science Fiction &amp; Fantasy / Fantasy / Historic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Cloud Cuckoo Land</td>\n",
       "      <td>Anthony Doerr</td>\n",
       "      <td>Fiction / Literary Fiction</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Book Name           Author  \\\n",
       "0                       A Calling for Charlie Barnes    Joshua Ferris   \n",
       "1                     Playing the Cards You're Dealt   Varian Johnson   \n",
       "2  Please Don't Sit on My Bed in Your Outside Clo...  Phoebe Robinson   \n",
       "3                                           Horseman  Christina Henry   \n",
       "4                                  Cloud Cuckoo Land    Anthony Doerr   \n",
       "\n",
       "                                               genre  \n",
       "0                             Fiction / Family Drama  \n",
       "1                          Children's / Middle Grade  \n",
       "2                        Nonfiction / Essays / Humor  \n",
       "3  Science Fiction & Fantasy / Fantasy / Historic...  \n",
       "4                         Fiction / Literary Fiction  "
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "page = requests.get('https://bookpage.com/reviews')\n",
    "\n",
    "soup = BeautifulSoup(page.content)\n",
    "\n",
    "books= soup.find_all('h4',class_='italic')\n",
    "\n",
    "book_names=[]\n",
    "for i in books:\n",
    "    book_names.append(i.text.replace('★','').replace('\\n',''))\n",
    "del book_names[5:]\n",
    "\n",
    "authors_script =soup.find_all('p',class_='sans bold')\n",
    "\n",
    "author_names=[]\n",
    "for i in authors_script:\n",
    "      author_names.append(i.text.strip())\n",
    "del author_names[5:]\n",
    "    \n",
    "#print(author_names)\n",
    "genre = soup.find_all('p',class_='genre-links hidden-phone')\n",
    "\n",
    "genre_list=[]\n",
    "for i in genre:\n",
    "    genre_list.append(i.text.strip().replace('\\n',''))\n",
    "        \n",
    "del genre_list[5:]\n",
    "#print(genre_list)\n",
    "    \n",
    "data=pd.DataFrame()\n",
    "data['Book Name']=book_names\n",
    "data['Author']=author_names\n",
    "data['genre']=genre_list\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q.5 Write a python program to scrape cricket rankings from www.icc-cricket.com You have to scrape:\n",
    "i) Top 10 ODI teams in men’s cricket along with the records for matches, points and rating.\n",
    "ii) Top 10 ODI Batsmen in men along with the records of their team and rating.\n",
    "iii) Top 10 ODI bowlers along with the records of their team andrating."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "i) Top 10 ODI teams in men’s cricket along with the records for matches, points and rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Teams</th>\n",
       "      <th>Ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ENG</td>\n",
       "      <td>119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AUS</td>\n",
       "      <td>116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>IND</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SA</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PAK</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>BAN</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>WI</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SL</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>AFG</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NED</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Teams Ratings\n",
       "0   ENG     119\n",
       "1   AUS     116\n",
       "2   IND     113\n",
       "3    SA      98\n",
       "4   PAK      93\n",
       "5   BAN      91\n",
       "6    WI      84\n",
       "7    SL      83\n",
       "8   AFG      62\n",
       "9   NED      48"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "page= requests.get('https://www.icc-cricket.com/rankings/mens/team-rankings/odi')\n",
    "\n",
    "soup = BeautifulSoup(page.content)\n",
    "\n",
    "Team = soup.find_all('span',class_='u-show-phablet')\n",
    "\n",
    "team_list=[]\n",
    "for i in Team:\n",
    "    team_list.append(i.text)\n",
    "del team_list[11:]\n",
    "team_list.pop(0)\n",
    "#print(teams)\n",
    "\n",
    "\n",
    "Rating= soup.find_all('td',class_='table-body__cell u-text-right rating')\n",
    "\n",
    "\n",
    "rating_list=[]\n",
    "for i in Rating:\n",
    "    rating_list.append(i.text)\n",
    "del rating_list[10:]\n",
    "#print(ratings)    \n",
    "\n",
    "data=pd.DataFrame()\n",
    "data['Teams'] = team_list\n",
    "data['Ratings'] = rating_list\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ii) Top 10 ODI Batsmen in men along with the records of their team and rating. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Batsmen</th>\n",
       "      <th>Teams</th>\n",
       "      <th>Ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Virat Kohli</td>\n",
       "      <td>IND</td>\n",
       "      <td>844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Rohit Sharma</td>\n",
       "      <td>IND</td>\n",
       "      <td>813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ross Taylor</td>\n",
       "      <td>NZ</td>\n",
       "      <td>801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Aaron Finch</td>\n",
       "      <td>AUS</td>\n",
       "      <td>779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Jonny Bairstow</td>\n",
       "      <td>ENG</td>\n",
       "      <td>775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>David Warner</td>\n",
       "      <td>AUS</td>\n",
       "      <td>762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Shai Hope</td>\n",
       "      <td>WI</td>\n",
       "      <td>758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Kane Williamson</td>\n",
       "      <td>NZ</td>\n",
       "      <td>754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Quinton de Kock</td>\n",
       "      <td>SA</td>\n",
       "      <td>747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Fakhar Zaman</td>\n",
       "      <td>PAK</td>\n",
       "      <td>741</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Batsmen Teams Ratings\n",
       "0      Virat Kohli   IND     844\n",
       "1     Rohit Sharma   IND     813\n",
       "2      Ross Taylor    NZ     801\n",
       "3      Aaron Finch   AUS     779\n",
       "4   Jonny Bairstow   ENG     775\n",
       "5     David Warner   AUS     762\n",
       "6        Shai Hope    WI     758\n",
       "7  Kane Williamson    NZ     754\n",
       "8  Quinton de Kock    SA     747\n",
       "9     Fakhar Zaman   PAK     741"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "page= requests.get('https://www.icc-cricket.com/rankings/mens/player-rankings/odi/batting')\n",
    "\n",
    "soup = BeautifulSoup(page.content)\n",
    "\n",
    "batsmen_list=soup.find_all('td',class_='table-body__cell rankings-table__name name')\n",
    "\n",
    "\n",
    "Batsmen_list=[]\n",
    "for i in batsmen_list:\n",
    "    Batsmen_list.append(i.text.replace('\\n',''))\n",
    "del Batsmen_list[10:]\n",
    "#print(Batsmen_list)\n",
    "\n",
    "Team_list=soup.find_all('span',class_='table-body__logo-text')\n",
    "\n",
    "\n",
    "team_list=[]\n",
    "for i in Team_list:\n",
    "    team_list.append(i.text)\n",
    "del team_list[10:]\n",
    "#print(team_list)\n",
    "\n",
    "Rating_list=soup.find_all('td',class_='rating')\n",
    "\n",
    "rating_list=[]\n",
    "for i in Rating_list:\n",
    "    rating_list.append(i.text)\n",
    "    \n",
    "del rating_list[10:]\n",
    "#print(rating_list)\n",
    "\n",
    "data=pd.DataFrame()\n",
    "data['Batsmen']=Batsmen_list\n",
    "data['Teams'] =team_list\n",
    "data['Ratings'] = rating_list\n",
    "\n",
    "\n",
    "data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " iii) Top 10 ODI bowlers along with the records of their team andrating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Bowlers</th>\n",
       "      <th>Teams</th>\n",
       "      <th>Ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Josh Hazlewood</td>\n",
       "      <td>AUS</td>\n",
       "      <td>709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mujeeb Ur Rahman</td>\n",
       "      <td>AFG</td>\n",
       "      <td>708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Chris Woakes</td>\n",
       "      <td>ENG</td>\n",
       "      <td>700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mehedi Hasan</td>\n",
       "      <td>BAN</td>\n",
       "      <td>692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Matt Henry</td>\n",
       "      <td>NZ</td>\n",
       "      <td>691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Jasprit Bumrah</td>\n",
       "      <td>IND</td>\n",
       "      <td>679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Mitchell Starc</td>\n",
       "      <td>AUS</td>\n",
       "      <td>652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Shakib Al Hasan</td>\n",
       "      <td>BAN</td>\n",
       "      <td>650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Kagiso Rabada</td>\n",
       "      <td>SA</td>\n",
       "      <td>646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Mustafizur Rahman</td>\n",
       "      <td>BAN</td>\n",
       "      <td>640</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Bowlers Teams Ratings\n",
       "0     Josh Hazlewood   AUS     709\n",
       "1   Mujeeb Ur Rahman   AFG     708\n",
       "2       Chris Woakes   ENG     700\n",
       "3       Mehedi Hasan   BAN     692\n",
       "4         Matt Henry    NZ     691\n",
       "5     Jasprit Bumrah   IND     679\n",
       "6     Mitchell Starc   AUS     652\n",
       "7    Shakib Al Hasan   BAN     650\n",
       "8      Kagiso Rabada    SA     646\n",
       "9  Mustafizur Rahman   BAN     640"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "page= requests.get('https://www.icc-cricket.com/rankings/mens/player-rankings/odi/bowling')\n",
    "\n",
    "soup = BeautifulSoup(page.content)\n",
    "\n",
    "bowler_list=soup.find_all('td',class_='table-body__cell rankings-table__name name')\n",
    "\n",
    "\n",
    "Bowler_list=[]\n",
    "for i in bowler_list:\n",
    "    Bowler_list.append(i.text.replace('\\n',''))\n",
    "del Bowler_list[10:]\n",
    "#print(Bowler_list)\n",
    "\n",
    "Team_list=soup.find_all('span',class_='table-body__logo-text')\n",
    "\n",
    "\n",
    "team_list=[]\n",
    "for i in Team_list:\n",
    "    team_list.append(i.text)\n",
    "del team_list[10:]\n",
    "#print(team_list)\n",
    "\n",
    "Rating_list=soup.find_all('td',class_='rating')\n",
    "\n",
    "rating_list=[]\n",
    "for i in Rating_list:\n",
    "    rating_list.append(i.text)\n",
    "    \n",
    "del rating_list[10:]\n",
    "#print(rating_list)\n",
    "\n",
    "data=pd.DataFrame()\n",
    "data['Bowlers']=Bowler_list\n",
    "data['Teams'] =team_list\n",
    "data['Ratings'] = rating_list\n",
    "\n",
    "\n",
    "data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q.6 Write a python program to scrape cricket rankings from www.icc-cricket.com You have to scrape:\n",
    "i) Top 10 ODI teams in women’s cricket along with the records for matches, points and rating.\n",
    "ii) Top 10 women’s ODI players along with the records of their team and rating.\n",
    "iii) Top 10 women’s ODI all-rounder along with the records of their team andrating.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "i) Top 10 ODI teams in women’s cricket along with the records for matches, points and rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Teams</th>\n",
       "      <th>Ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ENG</td>\n",
       "      <td>119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SA</td>\n",
       "      <td>117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>IND</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NZ</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>WI</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>PAK</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>BAN</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SL</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>IRE</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Teams Ratings\n",
       "0   ENG     119\n",
       "1    SA     117\n",
       "2   IND     113\n",
       "3    NZ      92\n",
       "4    WI      85\n",
       "5   PAK      75\n",
       "6   BAN      61\n",
       "7    SL      47\n",
       "8   IRE      13"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "page= requests.get('https://www.icc-cricket.com/rankings/womens/team-rankings/odi')\n",
    "\n",
    "soup = BeautifulSoup(page.content)\n",
    "\n",
    "Team_list= soup.find_all('span',class_='u-show-phablet')\n",
    "\n",
    "team_list=[]\n",
    "for i in Team_list:\n",
    "    team_list.append(i.text)\n",
    "del team_list[10:]\n",
    "team_list.pop(0)\n",
    "#print(team_list)\n",
    "\n",
    "\n",
    "Rating_list= soup.find_all('td',class_='table-body__cell u-text-right rating')\n",
    "\n",
    "\n",
    "rating_list=[]\n",
    "for i in Rating_list:\n",
    "    rating_list.append(i.text)\n",
    "del rating_list[10:]\n",
    "#print(rating_list)    \n",
    "\n",
    "data=pd.DataFrame()\n",
    "data['Teams'] = team_list\n",
    "data['Ratings'] = rating_list\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ii) Top 10 women’s ODI players along with the records of their team and rating."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " iii) Top 10 women’s ODI all-rounder along with the records of their team andrating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>All Rounders</th>\n",
       "      <th>Teams</th>\n",
       "      <th>Ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Josh Hazlewood</td>\n",
       "      <td>ENG</td>\n",
       "      <td>372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mujeeb Ur Rahman</td>\n",
       "      <td>AUS</td>\n",
       "      <td>365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Chris Woakes</td>\n",
       "      <td>WI</td>\n",
       "      <td>322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mehedi Hasan</td>\n",
       "      <td>IND</td>\n",
       "      <td>299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Matt Henry</td>\n",
       "      <td>AUS</td>\n",
       "      <td>275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Jasprit Bumrah</td>\n",
       "      <td>SA</td>\n",
       "      <td>274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Mitchell Starc</td>\n",
       "      <td>AUS</td>\n",
       "      <td>272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Shakib Al Hasan</td>\n",
       "      <td>ENG</td>\n",
       "      <td>272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Kagiso Rabada</td>\n",
       "      <td>IND</td>\n",
       "      <td>251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Mustafizur Rahman</td>\n",
       "      <td>NZ</td>\n",
       "      <td>248</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        All Rounders Teams Ratings\n",
       "0     Josh Hazlewood   ENG     372\n",
       "1   Mujeeb Ur Rahman   AUS     365\n",
       "2       Chris Woakes    WI     322\n",
       "3       Mehedi Hasan   IND     299\n",
       "4         Matt Henry   AUS     275\n",
       "5     Jasprit Bumrah    SA     274\n",
       "6     Mitchell Starc   AUS     272\n",
       "7    Shakib Al Hasan   ENG     272\n",
       "8      Kagiso Rabada   IND     251\n",
       "9  Mustafizur Rahman    NZ     248"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "page= requests.get('https://www.icc-cricket.com/rankings/womens/player-rankings/odi/all-rounder')\n",
    "\n",
    "soup = BeautifulSoup(page.content)\n",
    "\n",
    "rounder_list=soup.find_all('td',class_='table-body__cell rankings-table__name name')\n",
    "\n",
    "\n",
    "All_rounder_list=[]\n",
    "for i in rounder_list:\n",
    "    All_rounder_list.append(i.text.replace('\\n',''))\n",
    "del All_rounder_list[10:]\n",
    "#print(All_rounder_list)\n",
    "\n",
    "Team_list=soup.find_all('span',class_='table-body__logo-text')\n",
    "\n",
    "\n",
    "team_list=[]\n",
    "for i in Team_list:\n",
    "    team_list.append(i.text)\n",
    "del team_list[10:]\n",
    "#print(team_list)\n",
    "\n",
    "Rating_list=soup.find_all('td',class_='rating')\n",
    "\n",
    "rating_list=[]\n",
    "for i in Rating_list:\n",
    "    rating_list.append(i.text)\n",
    "    \n",
    "del rating_list[10:]\n",
    "#print(rating_list)\n",
    "\n",
    "data=pd.DataFrame()\n",
    "data['All Rounders']=Bowler_list\n",
    "data['Teams'] =team_list\n",
    "data['Ratings'] = rating_list\n",
    "\n",
    "\n",
    "data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q.7 Write a python program to scrape details of all the mobile phones under Rs. 20,000 listed on Amazon.in. The scraped data should include Product Name, Price, Image URL and Average Rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "page= requests.get('https://www.amazon.in/s?k=phone+under+20000&ref=nb_sb_noss_1')\n",
    "\n",
    "soup = BeautifulSoup(page.content)\n",
    "\n",
    "product_list= soup.find_all('h2',class_='a-size-mini a-spacing-none a-color-base s-line-clamp-2')\n",
    "\n",
    "\n",
    "product_names=[]\n",
    "for i in product_list:\n",
    "    product_name= (i.text)\n",
    "    print(product_name)\n",
    "    product_names.append(product_name)\n",
    "    \n",
    "#print(product_names)   \n",
    "  \n",
    "\n",
    "price_lists = soup.find_all('span', class_='a-price-whole')\n",
    "\n",
    "\n",
    "price_list=[]\n",
    "for i in Price_lists:\n",
    "    price_list.append(i.text)\n",
    "#print(price_list)    \n",
    "\n",
    "\n",
    "\n",
    "average_ratings= soup.find_all('span', class_='a-icon-alt')\n",
    "\n",
    "\n",
    "average_rating=[]\n",
    "for i in Average_ratings:\n",
    "    average_rating.append(i.text)\n",
    "\n",
    "#print(average_rating)\n",
    "\n",
    "data=pd.DataFrame()\n",
    "data['Product Name']=product_name\n",
    "data['Price']=price_list\n",
    "data['Average Ratings']=average_rating\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q.8 Write a python program to extract information about the local weather from the National Weather Service website of USA, https://www.weather.gov/ for the city, San Francisco. You need to extract data about 7 day extended forecast display for the city. The data should include period, short description, temperature and description.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Period</th>\n",
       "      <th>short description</th>\n",
       "      <th>Temperature and description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tonight</td>\n",
       "      <td>Mostly Clear</td>\n",
       "      <td>Mostly clear, with a low around 53. West wind ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Wednesday</td>\n",
       "      <td>Sunny</td>\n",
       "      <td>Sunny, with a high near 69. Light west wind in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>WednesdayNight</td>\n",
       "      <td>Mostly Clear</td>\n",
       "      <td>Mostly clear, with a low around 55. West wind ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Thursday</td>\n",
       "      <td>Sunny</td>\n",
       "      <td>Sunny, with a high near 75. Light and variable...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ThursdayNight</td>\n",
       "      <td>Mostly Clear</td>\n",
       "      <td>Mostly clear, with a low around 55. Southwest ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Friday</td>\n",
       "      <td>Sunny</td>\n",
       "      <td>Sunny, with a high near 74.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>FridayNight</td>\n",
       "      <td>Partly Cloudy</td>\n",
       "      <td>Partly cloudy, with a low around 55.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Period short description  \\\n",
       "0         Tonight      Mostly Clear   \n",
       "1       Wednesday             Sunny   \n",
       "2  WednesdayNight      Mostly Clear   \n",
       "3        Thursday             Sunny   \n",
       "4   ThursdayNight      Mostly Clear   \n",
       "5          Friday             Sunny   \n",
       "6     FridayNight     Partly Cloudy   \n",
       "\n",
       "                         Temperature and description  \n",
       "0  Mostly clear, with a low around 53. West wind ...  \n",
       "1  Sunny, with a high near 69. Light west wind in...  \n",
       "2  Mostly clear, with a low around 55. West wind ...  \n",
       "3  Sunny, with a high near 75. Light and variable...  \n",
       "4  Mostly clear, with a low around 55. Southwest ...  \n",
       "5                        Sunny, with a high near 74.  \n",
       "6               Partly cloudy, with a low around 55.  "
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "page= requests.get('https://forecast.weather.gov/MapClick.php?lat=37.777120000000025&lon=-122.41963999999996#.YU_8cOzivIU')\n",
    "\n",
    "soup = BeautifulSoup(page.content)\n",
    "\n",
    "Period=soup.find_all('p',class_='period-name')\n",
    "\n",
    "\n",
    "period=[]\n",
    "for i in Period:\n",
    "    period.append(i.text)\n",
    "#print(period)\n",
    "\n",
    "Short_description= soup.find_all('p',class_='short-desc')\n",
    "\n",
    "\n",
    "short_description=[]\n",
    "for i in Short_description:\n",
    "    short_description.append(i.text)\n",
    "#print(short_description)\n",
    "\n",
    "Temperature_description =soup.find_all('div',class_='col-sm-10 forecast-text')\n",
    "\n",
    "\n",
    "\n",
    "temperature_description=[]\n",
    "for i in Temperature_description:\n",
    "    temperature_description.append(i.text.strip())\n",
    "    \n",
    "del temperature_description[8:13]\n",
    "#print(temperature_description)\n",
    "\n",
    "data=pd.DataFrame()\n",
    "data['Period']=period\n",
    "data['short description']=short_description\n",
    "data['Temperature and description']=temperature_description\n",
    "data.head(7)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q.9 Write a python program to scrape fresher job listings from ‘https://internshala.com/’. It should include job title, company name, CTC, and apply date.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>House_title</th>\n",
       "      <th>company_name</th>\n",
       "      <th>ctc</th>\n",
       "      <th>apply_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Trainee Engineer</td>\n",
       "      <td>Moodraa</td>\n",
       "      <td>3.5 - 4 LPA</td>\n",
       "      <td>28-10-2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Software Engineer - Flutter/Dart</td>\n",
       "      <td>Aimed Labs</td>\n",
       "      <td>3 - 4 LPA</td>\n",
       "      <td>28-10-2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Associate Java Developer</td>\n",
       "      <td>HostBooks Limited</td>\n",
       "      <td>3 - 3.5 LPA</td>\n",
       "      <td>28-10-2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Android App Developer</td>\n",
       "      <td>WatchDeck</td>\n",
       "      <td>4.5 - 6 LPA</td>\n",
       "      <td>28-10-2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Support &amp; Installation Engineer</td>\n",
       "      <td>ENSOWT</td>\n",
       "      <td>3 LPA</td>\n",
       "      <td>28-10-2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Assistant Brand Manager</td>\n",
       "      <td>Pet Project India Private Limited</td>\n",
       "      <td>4.5 - 5.5 LPA</td>\n",
       "      <td>28-10-2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Associate Recruiter</td>\n",
       "      <td>Recruit CRM</td>\n",
       "      <td>4 LPA</td>\n",
       "      <td>28-10-2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Student Mentor - English</td>\n",
       "      <td>Kid Aptivity Technologies</td>\n",
       "      <td>3 - 3.6 LPA</td>\n",
       "      <td>28-10-2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Human Resources (HR) Manager</td>\n",
       "      <td>FreeCo Education Private Limited</td>\n",
       "      <td>3 - 4 LPA</td>\n",
       "      <td>28-10-2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Software Engineer - Trainee</td>\n",
       "      <td>RightRev India Private Limited</td>\n",
       "      <td>3 - 5 LPA</td>\n",
       "      <td>28-10-2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Embedded Systems Associate</td>\n",
       "      <td>Limelight</td>\n",
       "      <td>3 - 5 LPA</td>\n",
       "      <td>28-10-2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Business Development Associate</td>\n",
       "      <td>StayQrious India Private Limited</td>\n",
       "      <td>4 - 5 LPA</td>\n",
       "      <td>28-10-2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Social Media Executive</td>\n",
       "      <td>Plix - The Plant Flix</td>\n",
       "      <td>3 - 3.1 LPA</td>\n",
       "      <td>28-10-2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Digital Marketing Executive</td>\n",
       "      <td>Nebula Robotics</td>\n",
       "      <td>3 LPA</td>\n",
       "      <td>28-10-2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Market Research Associate</td>\n",
       "      <td>IndustryARC</td>\n",
       "      <td>3 - 3.5 LPA</td>\n",
       "      <td>28-10-2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>React Native Developer</td>\n",
       "      <td>Red Dot Apps</td>\n",
       "      <td>3 - 5 LPA</td>\n",
       "      <td>27-10-2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Associate Software Developer</td>\n",
       "      <td>Chimera Technologies</td>\n",
       "      <td>3 - 5 LPA</td>\n",
       "      <td>27-10-2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Associate Front End Developer</td>\n",
       "      <td>Seventh Triangle Consulting</td>\n",
       "      <td>3.5 - 3.7 LPA</td>\n",
       "      <td>27-10-2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Business Development Associate</td>\n",
       "      <td>Regional Public Relations</td>\n",
       "      <td>3 - 3.6 LPA</td>\n",
       "      <td>27-10-2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Lead Generation Associate</td>\n",
       "      <td>CommVersion Solutions</td>\n",
       "      <td>3 - 6 LPA</td>\n",
       "      <td>27-10-2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Business Development Associate</td>\n",
       "      <td>Web Assets</td>\n",
       "      <td>3 - 8 LPA</td>\n",
       "      <td>27-10-2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Accounts And MIS Manager</td>\n",
       "      <td>Little Olive</td>\n",
       "      <td>3 - 3.2 LPA</td>\n",
       "      <td>27-10-2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Junior Search Engine Optimization (SEO) Execut...</td>\n",
       "      <td>ICubes</td>\n",
       "      <td>3 LPA</td>\n",
       "      <td>27-10-2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Junior Equity Research Analyst</td>\n",
       "      <td>Saurashtra Freight Private Limited</td>\n",
       "      <td>3 - 3.5 LPA</td>\n",
       "      <td>27-10-2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Digital Marketing Associate</td>\n",
       "      <td>ActiveLoc</td>\n",
       "      <td>3 - 4 LPA</td>\n",
       "      <td>27-10-2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Associate Consultant</td>\n",
       "      <td>Peer Hunt</td>\n",
       "      <td>3 - 5 LPA</td>\n",
       "      <td>27-10-2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Software Developer</td>\n",
       "      <td>Vitra.ai</td>\n",
       "      <td>6.6 LPA</td>\n",
       "      <td>27-10-2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Cluster Manager</td>\n",
       "      <td>Gigforce Private Limited</td>\n",
       "      <td>4 - 6 LPA</td>\n",
       "      <td>27-10-2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Inside Sales Associate</td>\n",
       "      <td>Xobin</td>\n",
       "      <td>3.5 - 4.6 LPA</td>\n",
       "      <td>27-10-2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Marketing &amp; Sales Executive</td>\n",
       "      <td>Is You Skincare</td>\n",
       "      <td>3 - 4 LPA</td>\n",
       "      <td>25-10-2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>QA Engineer/Tester</td>\n",
       "      <td>Incrivelsoft Private Limited</td>\n",
       "      <td>3 LPA</td>\n",
       "      <td>25-10-2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Software Developer</td>\n",
       "      <td>Magnus Meditourism Private Limited</td>\n",
       "      <td>3 LPA</td>\n",
       "      <td>25-10-2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Career Strategist</td>\n",
       "      <td>Ace My Prep</td>\n",
       "      <td>6 LPA</td>\n",
       "      <td>25-10-2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Operations Support Staff</td>\n",
       "      <td>Alphamate Technologies</td>\n",
       "      <td>3 LPA</td>\n",
       "      <td>25-10-2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Business Development Associate</td>\n",
       "      <td>Amida Educational Services Private Limited</td>\n",
       "      <td>5 LPA</td>\n",
       "      <td>25-10-2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Online Business/Sales Driver</td>\n",
       "      <td>Root Bytes Agro Services Private Limited</td>\n",
       "      <td>3 - 3.5 LPA</td>\n",
       "      <td>25-10-2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Business Development Officer</td>\n",
       "      <td>Redwood Algorithms</td>\n",
       "      <td>3 - 6 LPA</td>\n",
       "      <td>25-10-2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Software Engineer</td>\n",
       "      <td>SenSei Technologies</td>\n",
       "      <td>3 - 3.2 LPA</td>\n",
       "      <td>25-10-2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Embedded Systems Specialist</td>\n",
       "      <td>Lazy Idli Private Limited</td>\n",
       "      <td>4.2 LPA</td>\n",
       "      <td>25-10-2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Omni Sports Leader</td>\n",
       "      <td>Decathlon Sports India</td>\n",
       "      <td>3 - 5 LPA</td>\n",
       "      <td>25-10-2021</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          House_title  \\\n",
       "0                                   Trainee Engineer    \n",
       "1                   Software Engineer - Flutter/Dart    \n",
       "2                           Associate Java Developer    \n",
       "3                              Android App Developer    \n",
       "4                    Support & Installation Engineer    \n",
       "5                            Assistant Brand Manager    \n",
       "6                                Associate Recruiter    \n",
       "7                           Student Mentor - English    \n",
       "8                       Human Resources (HR) Manager    \n",
       "9                        Software Engineer - Trainee    \n",
       "10                        Embedded Systems Associate    \n",
       "11                    Business Development Associate    \n",
       "12                            Social Media Executive    \n",
       "13                       Digital Marketing Executive    \n",
       "14                         Market Research Associate    \n",
       "15                            React Native Developer    \n",
       "16                      Associate Software Developer    \n",
       "17                     Associate Front End Developer    \n",
       "18                    Business Development Associate    \n",
       "19                         Lead Generation Associate    \n",
       "20                    Business Development Associate    \n",
       "21                          Accounts And MIS Manager    \n",
       "22  Junior Search Engine Optimization (SEO) Execut...   \n",
       "23                    Junior Equity Research Analyst    \n",
       "24                       Digital Marketing Associate    \n",
       "25                              Associate Consultant    \n",
       "26                                Software Developer    \n",
       "27                                   Cluster Manager    \n",
       "28                            Inside Sales Associate    \n",
       "29                       Marketing & Sales Executive    \n",
       "30                                QA Engineer/Tester    \n",
       "31                                Software Developer    \n",
       "32                                 Career Strategist    \n",
       "33                          Operations Support Staff    \n",
       "34                    Business Development Associate    \n",
       "35                      Online Business/Sales Driver    \n",
       "36                      Business Development Officer    \n",
       "37                                 Software Engineer    \n",
       "38                       Embedded Systems Specialist    \n",
       "39                                Omni Sports Leader    \n",
       "\n",
       "                                  company_name            ctc  apply_date  \n",
       "0                                      Moodraa    3.5 - 4 LPA  28-10-2021  \n",
       "1                                   Aimed Labs      3 - 4 LPA  28-10-2021  \n",
       "2                            HostBooks Limited    3 - 3.5 LPA  28-10-2021  \n",
       "3                                    WatchDeck    4.5 - 6 LPA  28-10-2021  \n",
       "4                                       ENSOWT          3 LPA  28-10-2021  \n",
       "5            Pet Project India Private Limited  4.5 - 5.5 LPA  28-10-2021  \n",
       "6                                  Recruit CRM          4 LPA  28-10-2021  \n",
       "7                    Kid Aptivity Technologies    3 - 3.6 LPA  28-10-2021  \n",
       "8             FreeCo Education Private Limited      3 - 4 LPA  28-10-2021  \n",
       "9               RightRev India Private Limited      3 - 5 LPA  28-10-2021  \n",
       "10                                   Limelight      3 - 5 LPA  28-10-2021  \n",
       "11            StayQrious India Private Limited      4 - 5 LPA  28-10-2021  \n",
       "12                       Plix - The Plant Flix    3 - 3.1 LPA  28-10-2021  \n",
       "13                             Nebula Robotics          3 LPA  28-10-2021  \n",
       "14                                 IndustryARC    3 - 3.5 LPA  28-10-2021  \n",
       "15                                Red Dot Apps      3 - 5 LPA  27-10-2021  \n",
       "16                        Chimera Technologies      3 - 5 LPA  27-10-2021  \n",
       "17                 Seventh Triangle Consulting  3.5 - 3.7 LPA  27-10-2021  \n",
       "18                   Regional Public Relations    3 - 3.6 LPA  27-10-2021  \n",
       "19                       CommVersion Solutions      3 - 6 LPA  27-10-2021  \n",
       "20                                  Web Assets      3 - 8 LPA  27-10-2021  \n",
       "21                                Little Olive    3 - 3.2 LPA  27-10-2021  \n",
       "22                                      ICubes          3 LPA  27-10-2021  \n",
       "23          Saurashtra Freight Private Limited    3 - 3.5 LPA  27-10-2021  \n",
       "24                                   ActiveLoc      3 - 4 LPA  27-10-2021  \n",
       "25                                   Peer Hunt      3 - 5 LPA  27-10-2021  \n",
       "26                                    Vitra.ai        6.6 LPA  27-10-2021  \n",
       "27                    Gigforce Private Limited      4 - 6 LPA  27-10-2021  \n",
       "28                                       Xobin  3.5 - 4.6 LPA  27-10-2021  \n",
       "29                             Is You Skincare      3 - 4 LPA  25-10-2021  \n",
       "30                Incrivelsoft Private Limited          3 LPA  25-10-2021  \n",
       "31          Magnus Meditourism Private Limited          3 LPA  25-10-2021  \n",
       "32                                 Ace My Prep          6 LPA  25-10-2021  \n",
       "33                      Alphamate Technologies          3 LPA  25-10-2021  \n",
       "34  Amida Educational Services Private Limited          5 LPA  25-10-2021  \n",
       "35    Root Bytes Agro Services Private Limited    3 - 3.5 LPA  25-10-2021  \n",
       "36                          Redwood Algorithms      3 - 6 LPA  25-10-2021  \n",
       "37                         SenSei Technologies    3 - 3.2 LPA  25-10-2021  \n",
       "38                   Lazy Idli Private Limited        4.2 LPA  25-10-2021  \n",
       "39                      Decathlon Sports India      3 - 5 LPA  25-10-2021  "
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from datetime import datetime\n",
    "from dateutil import parser\n",
    "import pandas as pd\n",
    "page = requests.get('https://internshala.com/fresher-jobs')\n",
    "soup = BeautifulSoup(page.content)\n",
    "titles = soup.find_all('div' ,class_='heading_4_5 profile')\n",
    "\n",
    "job_titles =[]\n",
    "\n",
    "for i in titles:\n",
    "    job_titles.append(i.text.replace('\\n',''))\n",
    "    \n",
    "companies=soup.find_all('a',class_='link_display_like_text')\n",
    "\n",
    "company_names =[]  \n",
    "\n",
    "for i in companies:\n",
    "    company_names.append(i.text.strip())\n",
    "    \n",
    " \n",
    "                        \n",
    "\n",
    "Apply_date=soup.find_all('div',class_='item_body')\n",
    "\n",
    "apply_dates=[]\n",
    "ctcs=[]\n",
    "res= True\n",
    "format = \"%d-%m-%Y\"\n",
    "for i in Apply_date:\n",
    "    apply_date=(i.text.replace('Starts\\xa0Immediately\\n',''))\n",
    "    apply_date=apply_date.strip()\n",
    "\n",
    "    try:\n",
    "      res = bool(parser.parse(apply_date))\n",
    "      if(res):\n",
    "           pr= parser.parse(apply_date)\n",
    "           \n",
    "           apply_dates.append(pr.strftime(format)) \n",
    "      \n",
    "    except ValueError:\n",
    "        if(len(apply_date) > 0):\n",
    "         ctcs.append(apply_date.strip())\n",
    "\n",
    "    \n",
    "\n",
    "data=pd.DataFrame()\n",
    "data['House_title']=job_titles\n",
    "data['company_name']=company_names\n",
    "data['ctc']=ctcs\n",
    "data['apply_date']=apply_dates\n",
    "data\n",
    "                                                 \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q.10 Write a python program to scrape house details from https://www.nobroker.in/ for any location. It should include house title, location, area, emi and price."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Location</th>\n",
       "      <th>Area(sqft)</th>\n",
       "      <th>EMI(Rs)</th>\n",
       "      <th>Price(Rupees)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2 BHK Apartment  For Sale  In Goel Ganga Hill ...</td>\n",
       "      <td>Goel Ganga Hill Mist GardenÂ  NIBM, Kondhwa, P...</td>\n",
       "      <td>1,050 sqft</td>\n",
       "      <td>32,669/Month</td>\n",
       "      <td>57 Lacs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2 BHK Apartment  For Sale  In Sobha Garnet In ...</td>\n",
       "      <td>Sobha GarnetÂ  Off NIBM Road, Kondhwa, Pune, M...</td>\n",
       "      <td>1,000 sqft</td>\n",
       "      <td>51,583/Month</td>\n",
       "      <td>90 Lacs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2 BHK Apartment  For Sale  In Suyog Laher In K...</td>\n",
       "      <td>Suyog LaherÂ  Near Sai Service, Kondhwa Budruk...</td>\n",
       "      <td>940 sqft</td>\n",
       "      <td>38,400/Month</td>\n",
       "      <td>67 Lacs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2 BHK Apartment  For Sale  In Notting Hill In ...</td>\n",
       "      <td>Notting HillÂ  Punyadham Ashram Road, Kondhwa ...</td>\n",
       "      <td>806 sqft</td>\n",
       "      <td>29,803/Month</td>\n",
       "      <td>52 Lacs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2 BHK Apartment  For Sale  In Gagan Avenue In ...</td>\n",
       "      <td>Gagan AvenueÂ  Opposite Kalyan Mangal Karyalay...</td>\n",
       "      <td>1,155 sqft</td>\n",
       "      <td>41,266/Month</td>\n",
       "      <td>72 Lacs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2 BHK Flat  For Sale  In Kondhwa Bk</td>\n",
       "      <td>Standalone Building, Simran Iris Sahyadri Park...</td>\n",
       "      <td>1,154 sqft</td>\n",
       "      <td>48,717/Month</td>\n",
       "      <td>85 Lacs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2 BHK Apartment  For Sale  In Marvel Albero In...</td>\n",
       "      <td>Marvel AlberoÂ  Kondhwa, opposite angraj dhaba</td>\n",
       "      <td>1,310 sqft</td>\n",
       "      <td>52,729/Month</td>\n",
       "      <td>92 Lacs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2 BHK Flat  For Sale  In Archana Hill Town In ...</td>\n",
       "      <td>Kausar Baugh, Kondhwa, Pune, Maharashtra 41104...</td>\n",
       "      <td>1,075 sqft</td>\n",
       "      <td>45,851/Month</td>\n",
       "      <td>80 Lacs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2 BHK Apartment  For Sale  In Sunshree Apartme...</td>\n",
       "      <td>Sunshree ApartmentÂ  NIBM, Pune-4RIMS Internat...</td>\n",
       "      <td>890 sqft</td>\n",
       "      <td>31,522/Month</td>\n",
       "      <td>55 Lacs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2 BHK Flat  For Sale  In Amba Vatika In Kondha...</td>\n",
       "      <td>Amba Vatika, NIBM Post Office Road, Kubera Gar...</td>\n",
       "      <td>875 sqft</td>\n",
       "      <td>28,657/Month</td>\n",
       "      <td>50 Lacs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title  \\\n",
       "0  2 BHK Apartment  For Sale  In Goel Ganga Hill ...   \n",
       "1  2 BHK Apartment  For Sale  In Sobha Garnet In ...   \n",
       "2  2 BHK Apartment  For Sale  In Suyog Laher In K...   \n",
       "3  2 BHK Apartment  For Sale  In Notting Hill In ...   \n",
       "4  2 BHK Apartment  For Sale  In Gagan Avenue In ...   \n",
       "5               2 BHK Flat  For Sale  In Kondhwa Bk    \n",
       "6  2 BHK Apartment  For Sale  In Marvel Albero In...   \n",
       "7  2 BHK Flat  For Sale  In Archana Hill Town In ...   \n",
       "8  2 BHK Apartment  For Sale  In Sunshree Apartme...   \n",
       "9  2 BHK Flat  For Sale  In Amba Vatika In Kondha...   \n",
       "\n",
       "                                            Location  Area(sqft)  \\\n",
       "0  Goel Ganga Hill Mist GardenÂ  NIBM, Kondhwa, P...  1,050 sqft   \n",
       "1  Sobha GarnetÂ  Off NIBM Road, Kondhwa, Pune, M...  1,000 sqft   \n",
       "2  Suyog LaherÂ  Near Sai Service, Kondhwa Budruk...    940 sqft   \n",
       "3  Notting HillÂ  Punyadham Ashram Road, Kondhwa ...    806 sqft   \n",
       "4  Gagan AvenueÂ  Opposite Kalyan Mangal Karyalay...  1,155 sqft   \n",
       "5  Standalone Building, Simran Iris Sahyadri Park...  1,154 sqft   \n",
       "6     Marvel AlberoÂ  Kondhwa, opposite angraj dhaba  1,310 sqft   \n",
       "7  Kausar Baugh, Kondhwa, Pune, Maharashtra 41104...  1,075 sqft   \n",
       "8  Sunshree ApartmentÂ  NIBM, Pune-4RIMS Internat...    890 sqft   \n",
       "9  Amba Vatika, NIBM Post Office Road, Kubera Gar...    875 sqft   \n",
       "\n",
       "        EMI(Rs) Price(Rupees)  \n",
       "0  32,669/Month       57 Lacs  \n",
       "1  51,583/Month       90 Lacs  \n",
       "2  38,400/Month       67 Lacs  \n",
       "3  29,803/Month       52 Lacs  \n",
       "4  41,266/Month       72 Lacs  \n",
       "5  48,717/Month       85 Lacs  \n",
       "6  52,729/Month       92 Lacs  \n",
       "7  45,851/Month       80 Lacs  \n",
       "8  31,522/Month       55 Lacs  \n",
       "9  28,657/Month       50 Lacs  "
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "page= requests.get('https://www.nobroker.in/property/sale/pune/National%20Institute%20of%20Bank%20Management?searchParam=W3sibGF0IjoxOC40NzY1MDAzLCJsb24iOjczLjkwMDY0MDUsInBsYWNlSWQiOiJDaElKRzJfSC1tWHF3anNSYl9xZlRBd2R2eFUiLCJwbGFjZU5hbWUiOiJOYXRpb25hbCBJbnN0aXR1dGUgb2YgQmFuayBNYW5hZ2VtZW50In1d&radius=2.0&type=BHK2&propertyAge=0')\n",
    "\n",
    "house_titles = []\n",
    "house_locations = []\n",
    "house_area = []\n",
    "house_emi = []\n",
    "house_price = []\n",
    "\n",
    "html_soup = BeautifulSoup(page.text,'html.parser')\n",
    "house_containers1 = html_soup.find_all('article')\n",
    "house_containers = html_soup.find_all('div', id=\"listCardContainer\")\n",
    "for house in house_containers1:\n",
    "   \n",
    "   title = (house.find('div','nb__2JHKO').find('h2').text.replace('\\n',''))\n",
    "   house_titles.append(title)\n",
    "   location = (house.find('div','nb__2CMjv').text.replace('\\n',''))\n",
    "   house_locations.append(location)\n",
    "   area = (house.find('div','nb__3oNyC').text.replace('\\n',''))\n",
    "   house_area.append(area)\n",
    "   emi = (house.find('div', id='roomType').text.replace('â\\x82¹',''))\n",
    "   house_emi.append(emi)\n",
    "   price = (house.find('div', id='minDeposit').find('span').text.replace('â\\x82¹',''))\n",
    "   house_price.append(price)\n",
    "\n",
    "cols = ['Title', 'Location', 'Area(sqft)', 'EMI(Rs)', 'Price(Rupees)']\n",
    "df_pune = pd.DataFrame({'Title': house_titles,\n",
    "                        'Location': house_locations,\n",
    "                        'Area(sqft)': house_area,\n",
    "                        'EMI(Rs)': house_emi,\n",
    "                        'Price(Rupees)': house_price})[cols]\n",
    "df_pune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
